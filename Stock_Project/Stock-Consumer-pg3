from kafka import KafkaConsumer
import json
import psycopg2
from psycopg2 import sql
import pandas as pd
import numpy as np

# PostgreSQL Database Configuration
db_config = {
    'user': 'postgres',
    'password': 'Amit@8709',
    'host': 'localhost',
    'port': '5432',  # Default port for PostgreSQL
    'dbname': 'postgres'  # Connect to default database to create 'stock' database
}

# Kafka Consumer Configuration
kafka_bootstrap_servers = ['localhost:9092']
kafka_topic = 'your_topic'  # Use the same topic as the producer

try:
    # Connect to PostgreSQL to create 'stock' database
    connection = psycopg2.connect(**db_config)
    connection.autocommit = True
    cursor = connection.cursor()
    
    # Create 'stock' database if it doesn't exist
    cursor.execute("SELECT 1 FROM pg_catalog.pg_database WHERE datname = 'stock'")
    exists = cursor.fetchone()
    if not exists:
        cursor.execute(sql.SQL("CREATE DATABASE {}").format(sql.Identifier('stock')))
        print("Database 'stock' created successfully.")
    cursor.close()
    connection.close()

    # Connect to the 'stock' database
    db_config['dbname'] = 'stock'
    connection = psycopg2.connect(**db_config)
    cursor = connection.cursor()

    # Create 'stock_data' table if it doesn't exist
    create_table_query = """
    CREATE TABLE IF NOT EXISTS stock_data (
        Date DATE,
        Symbol VARCHAR(10),
        Series VARCHAR(5),
        Prev_Close FLOAT,
        Open FLOAT,
        High FLOAT,
        Low FLOAT,
        Last FLOAT,
        Close FLOAT,
        VWAP FLOAT,
        Volume BIGINT,
        Turnover DOUBLE PRECISION,
        Trades INT,
        Deliverable_Volume BIGINT,
        Percent_Deliverable FLOAT
    );
    """
    cursor.execute(create_table_query)
    connection.commit()

    # Initialize Kafka Consumer
    consumer = KafkaConsumer(
        kafka_topic,
        bootstrap_servers=kafka_bootstrap_servers,
        auto_offset_reset='earliest',
        value_deserializer=lambda v: json.loads(v.decode('utf-8')),
        consumer_timeout_ms=10000  # Adjust based on your use case
    )

    insert_query = """
    INSERT INTO stock_data (Date, Symbol, Series, Prev_Close, Open, High, Low, Last, Close, VWAP, Volume, Turnover, Trades, Deliverable_Volume, Percent_Deliverable)
    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """

    # Consume messages from Kafka and insert into PostgreSQL
    for message in consumer:
        data = message.value
        
        # Replace NaN values with None for PostgreSQL
        data = {k: (None if pd.isna(v) else v) for k, v in data.items()}
        
        # Prepare data for insertion (make sure keys match column names)
        record = (
            data['Date'],
            data['Symbol'],
            data['Series'],
            data['Prev Close'],
            data['Open'],
            data['High'],
            data['Low'],
            data['Last'],
            data['Close'],
            data['VWAP'],
            data['Volume'],
            data['Turnover'],
            data['Trades'],
            data['Deliverable Volume'],
            data['%Deliverble']
        )

        # Insert the record into the database
        try:
            cursor.execute(insert_query, record)
            connection.commit()
            print(f"Inserted record for Date: {data['Date']}")
        except psycopg2.Error as e:
            print(f"Error inserting record: {e}")
            connection.rollback()
            continue

except psycopg2.Error as e:
    print(f"Error: {e}")

finally:
    if connection:
        cursor.close()
        connection.close()
        print("PostgreSQL connection is closed")

    # Close the Kafka consumer
    consumer.close()